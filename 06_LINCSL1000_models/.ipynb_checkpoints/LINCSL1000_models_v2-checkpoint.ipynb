{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5819169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 76 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "cardiotox_with_sider_inactives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3094968/1983872822.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    416\n",
      "0    223\n",
      "Name: Cardiotox (with SIDER inactives), dtype: int64\n",
      "1    65\n",
      "0    25\n",
      "Name: Cardiotox (with SIDER inactives), dtype: int64\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 639\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 31\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 31 candidates, totalling 155 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 11\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities: 100%|██████████████████████| 1/1 [01:28<00:00, 88.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardiotox_with_sider_actives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3094968/1983872822.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    620\n",
      "0     90\n",
      "Name: Cardiotox (with SIDER actives), dtype: int64\n",
      "1    65\n",
      "0    25\n",
      "Name: Cardiotox (with SIDER actives), dtype: int64\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 710\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 35\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities: 100%|█████████████████████| 1/1 [01:43<00:00, 103.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardiotox_with_sider_all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3094968/1983872822.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    620\n",
      "0    223\n",
      "Name: Cardiotox (with SIDER all), dtype: int64\n",
      "1    65\n",
      "0    25\n",
      "Name: Cardiotox (with SIDER all), dtype: int64\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 843\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 42\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 14\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 5\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities: 100%|██████████████████████| 1/1 [01:34<00:00, 94.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sider_cardiacdisorders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3094968/1983872822.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    585\n",
      "0    207\n",
      "Name: Cardiac disorders, dtype: int64\n",
      "1    93\n",
      "0    40\n",
      "Name: Cardiac disorders, dtype: int64\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 792\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 39\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 13\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 5\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities: 100%|██████████████████████| 1/1 [01:18<00:00, 78.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTrank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities:   0%|                              | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3094968/1983872822.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    416\n",
      "0     90\n",
      "Name: DICTrank, dtype: int64\n",
      "1    65\n",
      "0    25\n",
      "Name: DICTrank, dtype: int64\n",
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 20\n",
      "max_resources_: 506\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 25\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 9\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 3\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activities: 100%|██████████████████████| 1/1 [01:28<00:00, 88.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, matthews_corrcoef, average_precision_score, confusion_matrix\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('/home/ss2686/03_DICTrank')\n",
    "\n",
    "import argparse\n",
    "from scripts.evaluation_functions import evaluate_classifier, optimize_threshold_j_statistic\n",
    "\n",
    "# Initialize pandarallel for parallel processing\n",
    "pandarallel.initialize()\n",
    "import gzip\n",
    "\n",
    "data_path = '../data/processed_binarised__splits/'\n",
    "\n",
    "# Define the path to your gzip-compressed image_features.csv.gz file\n",
    "csv_file_path = '../data/LINCSL1000/LINCSL1000_processed.csv.gz'\n",
    "\n",
    "\n",
    "def create_molecule_dict(csv_file_path):\n",
    "    molecule_dict = {}\n",
    "\n",
    "    with gzip.open(csv_file_path, 'rt') as f:\n",
    "        next(f)  # Skip the first line (header)\n",
    "        for line in f:\n",
    "            data = line.strip().split(',')\n",
    "            smiles = data[0]\n",
    "            features = np.array(data[1:979], dtype=float)\n",
    "            molecule_dict[smiles] = features\n",
    "    \n",
    "    return molecule_dict\n",
    "\n",
    "# Assuming you call create_molecule_dict once to create the dictionary\n",
    "molecule_dict = create_molecule_dict(csv_file_path)\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def calculate_tanimoto_similarity(molecule1, molecule2):\n",
    "    molecule1_fp =  AllChem.GetMorganFingerprintAsBitVect(molecule1, 2, nBits=2048)\n",
    "    molecule2_fp =  AllChem.GetMorganFingerprintAsBitVect(molecule2, 2, nBits=2048)\n",
    "    return DataStructs.TanimotoSimilarity(molecule1_fp, molecule2_fp)\n",
    "\n",
    "def fetch_similar_profiles(smiles, exclude_smiles_set=None):\n",
    "    if exclude_smiles_set is None:\n",
    "        exclude_smiles_set = set()\n",
    "\n",
    "    query_mol = Chem.MolFromSmiles(smiles)\n",
    "    similar_profiles = []\n",
    "\n",
    "    for key_smiles in molecule_dict:\n",
    "        if key_smiles in exclude_smiles_set:\n",
    "            continue\n",
    "\n",
    "        key_mol = Chem.MolFromSmiles(key_smiles)\n",
    "        similarity = calculate_tanimoto_similarity(query_mol, key_mol)\n",
    "        if similarity > 0.7:\n",
    "            similar_profiles.append(molecule_dict[key_smiles])\n",
    "\n",
    "    if len(similar_profiles) > 0:\n",
    "        return np.mean(similar_profiles, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Modify the generate_cellpainting function\n",
    "def generate_lincs(smiles, behave=\"Train\", exclude_smiles_set=None):\n",
    "    profile = molecule_dict.get(smiles)\n",
    "    if profile is not None:\n",
    "        return profile\n",
    "    elif(behave==\"Train\"):\n",
    "        return fetch_similar_profiles(smiles, exclude_smiles_set)\n",
    "    else:\n",
    "        return molecule_dict.get(smiles, np.zeros(978, dtype=float))\n",
    "    \n",
    "results = {}\n",
    "held_out_results = []\n",
    "\n",
    "for dataset in os.listdir(data_path):\n",
    "    \n",
    "    # Exclude hidden files or directories like .ipynb_checkpoints\n",
    "    if dataset.startswith('.'):\n",
    "        continue\n",
    "    print(dataset)\n",
    "\n",
    "\n",
    "    # Get all the file names for this dataset\n",
    "    all_files = os.listdir(os.path.join(data_path, dataset))\n",
    "\n",
    "    # Extract activity names by removing the _train.csv.gz or _test.csv.gz from file names\n",
    "    activity_names = list(set([f.replace(\"_train.csv.gz\", \"\").replace(\"_test.csv.gz\", \"\")  for f in all_files if not f.startswith(\".ipynb_checkpoints\")]))\n",
    "\n",
    "    for activity in tqdm(activity_names, desc=\"Processing activities\"):\n",
    "        \n",
    "        train_path = os.path.join(data_path, dataset, f\"{activity}_train.csv.gz\")\n",
    "        test_path = os.path.join(data_path, dataset, f\"{activity}_test.csv.gz\")\n",
    "\n",
    "        train_df = pd.read_csv(train_path, compression='gzip')#.sample(20)\n",
    "        test_df = pd.read_csv(test_path, compression='gzip')#.sample(20)\n",
    "\n",
    "        train_smiles_set = set(train_df['Standardized_SMILES'].tolist())\n",
    "        test_smiles_set = set(test_df['Standardized_SMILES'].tolist())\n",
    "        \n",
    "        X_train = train_df['Standardized_SMILES'].parallel_apply(lambda x: generate_lincs(x, \"Train\", test_smiles_set))\n",
    "        X_train = np.array(X_train.to_list())\n",
    "        \n",
    "        X_test = test_df['Standardized_SMILES'].parallel_apply(lambda x: generate_lincs(x, \"Test\"))\n",
    "        X_test = np.array(X_test.to_list())\n",
    "        \n",
    "        y_train = train_df[activity]\n",
    "        y_test = test_df[activity]\n",
    "\n",
    "        failed_train_indices = [i for i, lincs in enumerate(X_train) if lincs is None]\n",
    "        failed_test_indices = [i for i, lincs in enumerate(X_test) if lincs is None]\n",
    "        \n",
    "        # Drop those indices from X_train, X_test, y_train, and y_test\n",
    "        X_train = np.delete(X_train, failed_train_indices, axis=0)\n",
    "        X_train = np.vstack(X_train)\n",
    "        y_train = y_train.drop(failed_train_indices).reset_index(drop=True)\n",
    "\n",
    "        X_test = np.delete(X_test, failed_test_indices, axis=0)\n",
    "        X_test = np.vstack(X_test)\n",
    "        y_test = y_test.drop(failed_test_indices).reset_index(drop=True)\n",
    "\n",
    "        # If you want to drop the rows from train_df and test_df as well\n",
    "        train_df = train_df.drop(failed_train_indices).reset_index(drop=True)\n",
    "        test_df = test_df.drop(failed_test_indices).reset_index(drop=True)\n",
    "        \n",
    "        print(train_df[activity].value_counts())\n",
    "        print(test_df[activity].value_counts())\n",
    "        \n",
    "        # Classification\n",
    "        model = RandomForestClassifier(n_jobs=40)\n",
    "            \n",
    "        # Hyperparameter Optimization\n",
    "        param_dist_classification = {'max_depth': randint(10, 20),\n",
    "                          'max_features': randint(40, 50),\n",
    "                          'min_samples_leaf': randint(5, 15),\n",
    "                          'min_samples_split': randint(5, 15),\n",
    "                          'n_estimators':[200, 300, 400, 500, 600],\n",
    "                          'bootstrap': [True, False],\n",
    "                          'oob_score': [False],\n",
    "                          'random_state': [42],\n",
    "                          'criterion': ['gini', 'entropy'],\n",
    "                          'n_jobs': [40],\n",
    "                          'class_weight' : [None, 'balanced']\n",
    "                         }\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)   \n",
    "            \n",
    "        classification_search = HalvingRandomSearchCV(\n",
    "                model,\n",
    "                param_dist_classification,\n",
    "                factor=3,\n",
    "                cv=inner_cv,\n",
    "                random_state=42,\n",
    "                verbose=1,\n",
    "                n_jobs=40)\n",
    "            \n",
    "        classification_search.fit(X_train, y_train)\n",
    "        best_model = classification_search.best_estimator_\n",
    "            \n",
    "        # Random Over-sampling and Threshold Optimization\n",
    "        sampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "            \n",
    "        pipeline = Pipeline(steps=[('sampler', sampler), ('model', best_model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "            \n",
    "        # Predict using threshold-optimized model\n",
    "        predictions_train = pipeline.predict(X_train)\n",
    "        probs_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "        probs_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        # Use the optimize_threshold_j_statistic function to find the best threshold\n",
    "        best_threshold = optimize_threshold_j_statistic(y_train, probs_train)\n",
    "        #Apply the best threshold to get binary predictions on the test data\n",
    "        predictions_test = (probs_test >= best_threshold).astype(int)\n",
    "            \n",
    "        # Calculate CV AUC using threshold-optimized model\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "        results[activity] = {\n",
    "                'CV_AUC_mean': np.mean(cv_scores),\n",
    "                'CV_AUC_std': np.std(cv_scores),\n",
    "                **evaluate_classifier(y_test, predictions_test, probs_test)\n",
    "            }\n",
    "   \n",
    "        \n",
    "        held_out_data = {\n",
    "            'Dataset': dataset,\n",
    "            \"Actviity\": activity,\n",
    "            'SMILES': test_df['Standardized_SMILES'],\n",
    "            'True_Value': y_test,\n",
    "            'Prediction': predictions_test,\n",
    "            'Probability': probs_test,\n",
    "            'Best_Threshold': best_threshold\n",
    "        }\n",
    "        \n",
    "        held_out_results.append(pd.DataFrame(held_out_data))  \n",
    "\n",
    "        #Save results at each step\n",
    "        pd.DataFrame(results).T.to_csv('./LINCSL1000_model_results.csv')\n",
    "            \n",
    "        \n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results).T.reset_index(drop=False)\n",
    "results_df = results_df.rename(columns={'index': 'endpoint'})\n",
    "results_df.to_csv('./LINCSL1000_model_results.csv', index=False)\n",
    "\n",
    "# Concatenate and save held-out test set results\n",
    "pd.concat(held_out_results).to_csv('./LINCSL1000_model_held_out_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd49ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Actviity</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>True_Value</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Best_Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardiotox_with_sider_inactives</td>\n",
       "      <td>Cardiotox (with SIDER inactives)</td>\n",
       "      <td>O=C(C1CCCCC1)[NH+]1CC(=O)[NH+]2CCc3ccccc3C2C1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619192</td>\n",
       "      <td>0.604273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardiotox_with_sider_inactives</td>\n",
       "      <td>Cardiotox (with SIDER inactives)</td>\n",
       "      <td>CC(C(=O)[O-])c1ccc(-c2ccccc2)c(F)c1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600085</td>\n",
       "      <td>0.604273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardiotox_with_sider_inactives</td>\n",
       "      <td>Cardiotox (with SIDER inactives)</td>\n",
       "      <td>C[NH+](C)CCC=C1c2ccccc2CCc2ccccc21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.602112</td>\n",
       "      <td>0.604273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardiotox_with_sider_inactives</td>\n",
       "      <td>Cardiotox (with SIDER inactives)</td>\n",
       "      <td>CC(=O)[NH+]1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618311</td>\n",
       "      <td>0.604273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardiotox_with_sider_inactives</td>\n",
       "      <td>Cardiotox (with SIDER inactives)</td>\n",
       "      <td>Cc1nccn1CC1CCc2c(c3ccccc3n2C)C1=O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606801</td>\n",
       "      <td>0.604273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>DICTrank</td>\n",
       "      <td>DICTrank</td>\n",
       "      <td>CCC1(c2ccccc2)C(=O)NCNC1=O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.809186</td>\n",
       "      <td>0.879318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>DICTrank</td>\n",
       "      <td>DICTrank</td>\n",
       "      <td>CCOC(=O)[NH+]1CCC(=C2c3ccc(Cl)cc3CCc3cccnc32)CC1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887670</td>\n",
       "      <td>0.879318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>DICTrank</td>\n",
       "      <td>DICTrank</td>\n",
       "      <td>CCCSc1ccc2[n-]c(=NC(=O)OC)[n-]c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862238</td>\n",
       "      <td>0.879318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>DICTrank</td>\n",
       "      <td>DICTrank</td>\n",
       "      <td>CCC[NH+](CCC)S(=O)(=O)c1ccc(C(=O)[O-])cc1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>0.879318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>DICTrank</td>\n",
       "      <td>DICTrank</td>\n",
       "      <td>CC[NH+](CC)C(=S)SSC(=S)[NH+](CC)CC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812207</td>\n",
       "      <td>0.879318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dataset                          Actviity  \\\n",
       "0    cardiotox_with_sider_inactives  Cardiotox (with SIDER inactives)   \n",
       "1    cardiotox_with_sider_inactives  Cardiotox (with SIDER inactives)   \n",
       "2    cardiotox_with_sider_inactives  Cardiotox (with SIDER inactives)   \n",
       "3    cardiotox_with_sider_inactives  Cardiotox (with SIDER inactives)   \n",
       "4    cardiotox_with_sider_inactives  Cardiotox (with SIDER inactives)   \n",
       "..                              ...                               ...   \n",
       "488                        DICTrank                          DICTrank   \n",
       "489                        DICTrank                          DICTrank   \n",
       "490                        DICTrank                          DICTrank   \n",
       "491                        DICTrank                          DICTrank   \n",
       "492                        DICTrank                          DICTrank   \n",
       "\n",
       "                                                SMILES  True_Value  \\\n",
       "0        O=C(C1CCCCC1)[NH+]1CC(=O)[NH+]2CCc3ccccc3C2C1           1   \n",
       "1                  CC(C(=O)[O-])c1ccc(-c2ccccc2)c(F)c1           1   \n",
       "2                   C[NH+](C)CCC=C1c2ccccc2CCc2ccccc21           1   \n",
       "3    CC(=O)[NH+]1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(...           1   \n",
       "4                    Cc1nccn1CC1CCc2c(c3ccccc3n2C)C1=O           1   \n",
       "..                                                 ...         ...   \n",
       "488                         CCC1(c2ccccc2)C(=O)NCNC1=O           0   \n",
       "489   CCOC(=O)[NH+]1CCC(=C2c3ccc(Cl)cc3CCc3cccnc32)CC1           0   \n",
       "490                 CCCSc1ccc2[n-]c(=NC(=O)OC)[n-]c2c1           0   \n",
       "491          CCC[NH+](CCC)S(=O)(=O)c1ccc(C(=O)[O-])cc1           0   \n",
       "492                 CC[NH+](CC)C(=S)SSC(=S)[NH+](CC)CC           0   \n",
       "\n",
       "     Prediction  Probability  Best_Threshold  \n",
       "0             1     0.619192        0.604273  \n",
       "1             0     0.600085        0.604273  \n",
       "2             0     0.602112        0.604273  \n",
       "3             1     0.618311        0.604273  \n",
       "4             1     0.606801        0.604273  \n",
       "..          ...          ...             ...  \n",
       "488           0     0.809186        0.879318  \n",
       "489           1     0.887670        0.879318  \n",
       "490           0     0.862238        0.879318  \n",
       "491           0     0.790788        0.879318  \n",
       "492           0     0.812207        0.879318  \n",
       "\n",
       "[493 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./LINCSL1000_model_held_out_test_results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee209fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standardized_SMILES</th>\n",
       "      <th>Standardized_InChI</th>\n",
       "      <th>DICTrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=c1n(CCC[NH+]2CCN(c3cccc(Cl)c3)CC2)nc2ccccn12</td>\n",
       "      <td>InChI=1S/C19H22ClN5O/c20-16-5-3-6-17(15-16)23-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C(=O)[O-])c1ccc(-c2ccccc2)c(F)c1</td>\n",
       "      <td>InChI=1S/C15H13FO2/c1-10(15(17)18)12-7-8-13(14...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C[NH+](C)CCC=C1c2ccccc2CCc2ccccc21</td>\n",
       "      <td>InChI=1S/C20H23N/c1-21(2)15-7-12-20-18-10-5-3-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(=O)[NH+]1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(...</td>\n",
       "      <td>InChI=1S/C26H28Cl2N4O4/c1-19(33)31-10-12-32(13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1nccn1CC1CCc2c(c3ccccc3n2C)C1=O</td>\n",
       "      <td>InChI=1S/C18H19N3O/c1-12-19-9-10-21(12)11-13-7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>CCC1(c2ccccc2)C(=O)NCNC1=O</td>\n",
       "      <td>InChI=1S/C12H14N2O2/c1-2-12(9-6-4-3-5-7-9)10(1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CCOC(=O)[NH+]1CCC(=C2c3ccc(Cl)cc3CCc3cccnc32)CC1</td>\n",
       "      <td>InChI=1S/C22H23ClN2O2/c1-2-27-22(26)25-12-9-15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CCCSc1ccc2[n-]c(=NC(=O)OC)[n-]c2c1</td>\n",
       "      <td>InChI=1S/C12H14N3O2S/c1-3-6-18-8-4-5-9-10(7-8)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CCC[NH+](CCC)S(=O)(=O)c1ccc(C(=O)[O-])cc1</td>\n",
       "      <td>InChI=1S/C13H19NO4S/c1-3-9-14(10-4-2)19(17,18)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>CC[NH+](CC)C(=S)SSC(=S)[NH+](CC)CC</td>\n",
       "      <td>InChI=1S/C10H20N2S4/c1-5-11(6-2)9(13)15-16-10(...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Standardized_SMILES  \\\n",
       "0      O=c1n(CCC[NH+]2CCN(c3cccc(Cl)c3)CC2)nc2ccccn12   \n",
       "1                 CC(C(=O)[O-])c1ccc(-c2ccccc2)c(F)c1   \n",
       "2                  C[NH+](C)CCC=C1c2ccccc2CCc2ccccc21   \n",
       "3   CC(=O)[NH+]1CCN(c2ccc(OCC3COC(Cn4ccnc4)(c4ccc(...   \n",
       "4                   Cc1nccn1CC1CCc2c(c3ccccc3n2C)C1=O   \n",
       "..                                                ...   \n",
       "85                         CCC1(c2ccccc2)C(=O)NCNC1=O   \n",
       "86   CCOC(=O)[NH+]1CCC(=C2c3ccc(Cl)cc3CCc3cccnc32)CC1   \n",
       "87                 CCCSc1ccc2[n-]c(=NC(=O)OC)[n-]c2c1   \n",
       "88          CCC[NH+](CCC)S(=O)(=O)c1ccc(C(=O)[O-])cc1   \n",
       "89                 CC[NH+](CC)C(=S)SSC(=S)[NH+](CC)CC   \n",
       "\n",
       "                                   Standardized_InChI  DICTrank  \n",
       "0   InChI=1S/C19H22ClN5O/c20-16-5-3-6-17(15-16)23-...         1  \n",
       "1   InChI=1S/C15H13FO2/c1-10(15(17)18)12-7-8-13(14...         1  \n",
       "2   InChI=1S/C20H23N/c1-21(2)15-7-12-20-18-10-5-3-...         1  \n",
       "3   InChI=1S/C26H28Cl2N4O4/c1-19(33)31-10-12-32(13...         1  \n",
       "4   InChI=1S/C18H19N3O/c1-12-19-9-10-21(12)11-13-7...         1  \n",
       "..                                                ...       ...  \n",
       "85  InChI=1S/C12H14N2O2/c1-2-12(9-6-4-3-5-7-9)10(1...         0  \n",
       "86  InChI=1S/C22H23ClN2O2/c1-2-27-22(26)25-12-9-15...         0  \n",
       "87  InChI=1S/C12H14N3O2S/c1-3-6-18-8-4-5-9-10(7-8)...         0  \n",
       "88  InChI=1S/C13H19NO4S/c1-3-9-14(10-4-2)19(17,18)...         0  \n",
       "89  InChI=1S/C10H20N2S4/c1-5-11(6-2)9(13)15-16-10(...         0  \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba4dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "85    0\n",
       "86    0\n",
       "87    0\n",
       "88    0\n",
       "89    0\n",
       "Name: DICTrank, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a382c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
